 Instructions
Overview: You are the Lead Data Scientist for AdventureWorks, a global bicycle manufacturer and retailer. The executive team has tasked you with a comprehensive audit of sales performance and a customer segmentation analysis to drive the upcoming fiscal strategy.

Requirements:

You must use engine="pyarrow" for all data ingestion.

You must enable pd.options.mode.copy_on_write = True.

Visualizations must be clear, labeled, and statistically relevant.

Code must be modular, commented, and handle potential data quality issues (nulls, orphans).

Phase I: Environment Setup
Objective: Configure a modern Pandas 2.0+ environment.

Action: Import necessary libraries (pandas, numpy, matplotlib, seaborn, pyarrow, sklearn).

Crucial Step: Enable Copy-on-Write using pd.set_option("mode.copy_on_write", True). This ensures predictable memory handling and eliminates the SettingWithCopyWarning.

Phase II: Data Ingestion & Typing
Objective: Load the four CSV files (customers.csv, product.csv, orderheader.csv, orderdetails.csv).

Constraint: You must use the dtype_backend="pyarrow" argument in read_csv.

Verification: Print the dtypes of the loaded dataframes to confirm that strings are stored as string[pyarrow] and integers as int64[pyarrow].

Phase III: Data Cleaning & Relational Transformation
Date Parsing: Convert OrderDate, DueDate, and ShipDate in the header table to datetime objects.

Integrity Check: Verify that all CustomerIDs in the order headers exist in the customer master list.

Denormalization: Perform a hierarchical merge to create an Analytical Master Table (AMT):

Start with orderheader.

Left Join customers on CustomerID.

Inner Join orderdetails on SalesOrderID (we only want orders with items).

Left Join product on ProductID.

Feature Engineering: Calculate GrossMargin for each line item: (UnitPrice - StandardCost) * OrderQty. Handle any nulls in StandardCost conservatively (fill with 0).

Phase IV: Exploratory Data Analysis (EDA)
Sales Distribution: specific summary statistics for LineTotal.

Top Products: Identify the top 5 products by total revenue.

Temporal Analysis: Aggregate revenue by OrderYear to visualize trends.

Sales Performance: Extract the clean username from the SalesPerson column (remove the adventure-works\ prefix) and identify the top 3 sales representatives.

Phase V: RFM Feature Engineering
Theory: RFM (Recency, Frequency, Monetary) is a marketing technique used to rank and group customers.

Snapshot Date: Define a snapshot date as the maximum OrderDate in the dataset + 1 day.

Aggregation: Group by CustomerID and calculate:

Recency: Days since the last order (Snapshot - Max(OrderDate)).

Frequency: Count of unique SalesOrderID.

Monetary: Sum of LineTotal.

Scaling: Apply a Log Transformation (np.log1p) to the RFM values to handle skewness, then standardize using StandardScaler.

Phase VI & VII: Clustering & Evaluation
Clustering: Initialize a K-Means model (use K=4 for this exercise). Fit the model to the scaled RFM data.

Assignment: Assign the resulting Cluster IDs back to the original (non-scaled) RFM dataframe.

Evaluation: Calculate the Silhouette Score to evaluate the separation of your clusters.

Profiling: Group by the new Cluster column and calculate the mean Recency, Frequency, and Monetary values to interpret the "persona" of each cluster (e.g., "Whales", "Lapsed", "New").

Phase VIII: Reporting
Final Output: Merge the Cluster labels back to the main customers dataframe.

Labeling: Create a function to apply string labels (e.g., "VIP", "At Risk") based on the cluster profiles derived in the previous step.

Export: Save the final segmented customer list to AdventureWorks_Customer_Segmentation.csv.

4. Statistical and Business Analysis of the Solution
The solution code (provided below) implements a sophisticated analytics pipeline that yields specific business intelligence.

Cluster Analysis: The K-Means algorithm typically isolates four distinct behavioral groups in retail datasets like AdventureWorks:

The "Whales": These customers will exhibit the highest "Monetary" mean and relatively high "Frequency". In the AdventureWorks context, these are likely the B2B entities (Bike Stores) purchasing inventory. The strategic recommendation is Account Managementâ€”assigning dedicated sales reps to maintain these high-value relationships.

The "Lapsed": Characterized by high "Recency" (long time since last purchase). These customers represent churn risk. The recommendation is Re-engagement Campaigns via the EmailAddress provided in the final report.

The "New/Low Value": Customers with low frequency (often 1) and low recency. These are recent acquisitions. The goal is Cross-Selling to increase their basket size and move them into the "Regular" segment.

The "Regulars": Average scores across the board. They provide the steady cash flow but require Loyalty Programs to prevent them from drifting to competitors.

Technical Performance: By utilizing dtype_backend="pyarrow", the memory footprint of the customers and orderdetails DataFrames is reduced by approximately 30-50% compared to standard NumPy object arrays, primarily due to the efficient string encoding of the rowguid and EmailAddress columns. The pd.merge operations in Phase III are significantly faster (often 2-3x) due to the optimized hash join implementations available when using Arrow-backed data. Finally, the Copy-on-Write setting ensures that the heavy slicing and feature engineering in Phase V does not inadvertently duplicate the massive AMT dataframe in memory, preventing potential MemoryError on constrained environments.